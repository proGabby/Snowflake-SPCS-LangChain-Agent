services:
  # Snowflake LangChain Agent
  snowflake-agent:
    build:
      context: ..
      dockerfile: docker/Dockerfile
    container_name: snowflake-langchain-agent
    ports:
      - "8000:8000"
    environment:
      # Snowflake Configuration
      - SNOWFLAKE_ACCOUNT=${SNOWFLAKE_ACCOUNT}
      - SNOWFLAKE_USER=${SNOWFLAKE_USER}
      - SNOWFLAKE_PASSWORD=${SNOWFLAKE_PASSWORD}
      - SNOWFLAKE_WAREHOUSE=${SNOWFLAKE_WAREHOUSE}
      - SNOWFLAKE_DATABASE=${SNOWFLAKE_DATABASE}
      - SNOWFLAKE_SCHEMA=${SNOWFLAKE_SCHEMA}
      - SNOWFLAKE_ROLE=${SNOWFLAKE_ROLE}
      
      # vLLM Configuration (pointing to mock service)
      - VLLM_BASE_URL=http://mock-vllm:8000
      - VLLM_MODEL_NAME=microsoft/DialoGPT-small
      - VLLM_TIMEOUT=30
      - VLLM_MAX_RETRIES=3
      
      # Auth Configuration
      - SECRET_KEY=${SECRET_KEY:-your-secret-key-here}
      - AUTH_ALGORITHM=HS256
      - ACCESS_TOKEN_EXPIRE_MINUTES=30
      - ALLOWED_ORIGINS=http://localhost:3000,http://localhost:8000
      - ALLOWED_METHODS=GET,POST,PUT,DELETE,OPTIONS
      
      # App Configuration
      - LOG_LEVEL=INFO
      - ENVIRONMENT=development
    depends_on:
      - mock-vllm
    networks:
      - snowflake_llm_network
    restart: unless-stopped

  # Lightweight Mock vLLM Service
  mock-vllm:
    build:
      context: ..
      dockerfile: docker/Dockerfile.mock-vllm
    container_name: mock-vllm-service
    ports:
      - "8001:8000"
    networks:
      - snowflake_llm_network
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 256M

volumes:
  vllm_cache:

networks:
  snowflake_llm_network:
    driver: bridge
